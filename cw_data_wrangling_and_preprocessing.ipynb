{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f6e4553",
   "metadata": {},
   "source": [
    "## Data Wrangling And Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcbf6e4",
   "metadata": {},
   "source": [
    "Data wrangling is the process of removing errors and combining complex dataset to make them more accessible and easier to analyze. Before analyzing the dataset, we have to do this by the objective we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3946d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_tr = pd.read_csv('./training_set_values.csv', index_col=0)\n",
    "df_tr_lable = pd.read_csv('./training_set_lable.csv', index_col=0)\n",
    "df_test = pd.read_csv('./test_set_values.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a526e3",
   "metadata": {},
   "source": [
    "##### Step 1:\n",
    "Drop useless columns to make dataset lighter and easier. \n",
    "\n",
    "a. `num_private`: This column does not have a specific description, and the field is almost filled with `0`, the column should be dropped.\n",
    "\n",
    "b. The following groups of column have similar meaning, it could be simplified and remain only one column.\n",
    "\n",
    "(`funder`, `installer`),\n",
    "\n",
    "(`extraction_type`, `extraction_type_group`, `extraction_type_class`),\n",
    "\n",
    "(`scheme_management`, `management`)\n",
    "\n",
    "(`payment`, `payment_type`),\n",
    "\n",
    "(`water_quality`, `quality_group`),\n",
    "\n",
    "(`quantity`, `quantity_group`),\n",
    "\n",
    "(`source`, `source_type`),\n",
    "\n",
    "(`waterpoint_type`, `waterpoint_type_group`),\n",
    "\n",
    "\n",
    "c. `region_code`, `district_code`, `region`, `wpt_name`, `lga`, `ward` are all geographic related info that only indicates area name, it seems do not have any impact to the model and result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f36a00c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    delete_columns = [\n",
    "        'num_private', 'installer', 'extraction_type_group','extraction_type_class',\n",
    "        'management', 'payment', 'water_quality', 'quantity', 'source', 'waterpoint_type',\n",
    "        'region_code', 'district_code', 'region', 'wpt_name', 'lga', 'ward'\n",
    "    ]\n",
    "    df.drop(delete_columns, axis=1, inplace=True)\n",
    "\n",
    "drop_columns(df_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0245dab1",
   "metadata": {},
   "source": [
    "##### Step 2:\n",
    "\n",
    "Some columns may have a large number of enum items. It could take the enumeration value with the highest frequency, and replace the rest of `other`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "54f031e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top5_values(df, column_name):\n",
    "    return df[column_name].value_counts().nlargest(5).index.tolist()\n",
    "\n",
    "def divede(row, ls, str):\n",
    "    return row[str] if row[str] in ls else 'other'\n",
    "\n",
    "def classify(df):\n",
    "    column_list = ['funder', 'scheme_management']\n",
    "    for i in column_list:\n",
    "        df[i] = df.apply(divede, args=(top5_values(df, i), i), axis=1)\n",
    "\n",
    "classify(df_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cc0cfb",
   "metadata": {},
   "source": [
    "##### Step 3:\n",
    "Quick went through the dataset, write a script to check out all NaN value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6c52bbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`subvillage` has 371 Nan value, portion: 0.62%\n",
      "`public_meeting` has 3334 Nan value, portion: 5.61%\n",
      "`scheme_name` has 28166 Nan value, portion: 47.42%\n",
      "`permit` has 3056 Nan value, portion: 5.14%\n"
     ]
    }
   ],
   "source": [
    "def check_invalid(df):\n",
    "    rows_num = df.shape[0]\n",
    "    for col in df.columns:\n",
    "        col_isna_num = df[col].isna().sum()\n",
    "        if col_isna_num > 0:\n",
    "            print('`{}` has {} Nan value, portion: {:.2%}'.format(col, col_isna_num, col_isna_num/rows_num))\n",
    "\n",
    "check_invalid(df_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe55f958",
   "metadata": {},
   "source": [
    "##### Step 4:\n",
    "Dealing with the missing values, Fill the missing values as `unknown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3cca767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing(df):\n",
    "    df['subvillage'].fillna('unknown', inplace=True)\n",
    "    df['public_meeting'].fillna('unknown', inplace=True)\n",
    "    df['scheme_name'].fillna('unknown', inplace=True)\n",
    "    df['permit'].fillna('unknown', inplace=True)\n",
    "\n",
    "handle_missing(df_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce725622",
   "metadata": {},
   "source": [
    "##### Step 5:\n",
    "Drop duplicate rows in the dataset. As the result, the dataset do not contain duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b4ffa83e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows before deduplicate: 59400 rows\n",
      "number of rows after deduplicate: 59229 rows\n"
     ]
    }
   ],
   "source": [
    "def drop_duplicate(df):\n",
    "    print('number of rows before deduplicate: {} rows'.format(df.shape[0]))\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print('number of rows after deduplicate: {} rows'.format(df.shape[0]))\n",
    "    \n",
    "drop_duplicate(df_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fde632c",
   "metadata": {},
   "source": [
    "##### Step 6:\n",
    "Combine the lable to the traing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0afecfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59363 entries, 69572 to 26348\n",
      "Data columns (total 40 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   amount_tsh             59363 non-null  float64\n",
      " 1   date_recorded          59363 non-null  object \n",
      " 2   funder                 59363 non-null  object \n",
      " 3   gps_height             59363 non-null  int64  \n",
      " 4   installer              59363 non-null  object \n",
      " 5   longitude              59363 non-null  float64\n",
      " 6   latitude               59363 non-null  float64\n",
      " 7   wpt_name               59363 non-null  object \n",
      " 8   num_private            59363 non-null  int64  \n",
      " 9   basin                  59363 non-null  object \n",
      " 10  subvillage             59363 non-null  object \n",
      " 11  region                 59363 non-null  object \n",
      " 12  region_code            59363 non-null  int64  \n",
      " 13  district_code          59363 non-null  int64  \n",
      " 14  lga                    59363 non-null  object \n",
      " 15  ward                   59363 non-null  object \n",
      " 16  population             59363 non-null  int64  \n",
      " 17  public_meeting         59363 non-null  object \n",
      " 18  recorded_by            59363 non-null  object \n",
      " 19  scheme_management      59363 non-null  object \n",
      " 20  scheme_name            59363 non-null  object \n",
      " 21  permit                 59363 non-null  object \n",
      " 22  construction_year      59363 non-null  int64  \n",
      " 23  extraction_type        59363 non-null  object \n",
      " 24  extraction_type_group  59363 non-null  object \n",
      " 25  extraction_type_class  59363 non-null  object \n",
      " 26  management             59363 non-null  object \n",
      " 27  management_group       59363 non-null  object \n",
      " 28  payment                59363 non-null  object \n",
      " 29  payment_type           59363 non-null  object \n",
      " 30  water_quality          59363 non-null  object \n",
      " 31  quality_group          59363 non-null  object \n",
      " 32  quantity               59363 non-null  object \n",
      " 33  quantity_group         59363 non-null  object \n",
      " 34  source                 59363 non-null  object \n",
      " 35  source_type            59363 non-null  object \n",
      " 36  source_class           59363 non-null  object \n",
      " 37  waterpoint_type        59363 non-null  object \n",
      " 38  waterpoint_type_group  59363 non-null  object \n",
      " 39  status                 59363 non-null  object \n",
      "dtypes: float64(3), int64(6), object(31)\n",
      "memory usage: 18.6+ MB\n"
     ]
    }
   ],
   "source": [
    "def merge_label(df, df_lable):\n",
    "    for i, row in df.iterrows():\n",
    "        df['status'] = df_lable.loc[i]['status_group']\n",
    "    df.info()\n",
    "\n",
    "merge_label(df_tr, df_tr_lable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb403b13",
   "metadata": {},
   "source": [
    "##### Step 7:\n",
    "The test data set needs to do the same process as training date set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dd63ebbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows before deduplicate: 14850 rows\n",
      "number of rows after deduplicate: 14841 rows\n"
     ]
    }
   ],
   "source": [
    "drop_columns(df_test)\n",
    "handle_missing(df_test)\n",
    "drop_duplicate(df_test)\n",
    "classify(df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
